<?xml version="1.0" encoding="UTF-8" standalone="no"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" version="2.0">
  <channel>
    <title>Ars Technica - All content</title>
    <atom:link href="https://arstechnica.com/feed/" rel="self" type="application/rss+xml"/>
    <link>https://arstechnica.com</link>
    <description>All Ars Technica stories</description>
    <lastBuildDate>Thu, 12 Dec 2024 23:15:24 +0000</lastBuildDate>
    <language>en-US</language>
    <sy:updatePeriod>
      hourly    </sy:updatePeriod>
    <sy:updateFrequency>
      1    </sy:updateFrequency>
    
<image>
	<url>https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-60x60.png</url>
	<title>Ars Technica</title>
	<link>https://arstechnica.com</link>
	<width>32</width>
	<height>32</height>
</image> 
      <item>
        <title>Are LLMs capable of non-verbal reasoning?</title>
        <link>https://arstechnica.com/ai/2024/12/are-llms-capable-of-non-verbal-reasoning/</link>
                  <comments>https://arstechnica.com/ai/2024/12/are-llms-capable-of-non-verbal-reasoning/#comments</comments>
        
        <dc:creator>
          <![CDATA[Kyle Orland]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 21:55:20 +0000</pubDate>
        		<category><![CDATA[AI]]></category>
        <guid isPermaLink="true">https://arstechnica.com/ai/2024/12/are-llms-capable-of-non-verbal-reasoning/</guid>

                  <description>
            <![CDATA[Processing in the "latent space" could help AI with tricky logical questions.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>Large language models have found great success so far by <a href="https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/" target="_blank" rel="noopener">using their transformer architecture</a> to <a href="https://arstechnica.com/ai/2024/05/heres-whats-really-going-on-inside-an-llms-neural-network/" target="_blank" rel="noopener">effectively predict the next words</a> (i.e., language tokens) needed to respond to queries. When it comes to complex reasoning tasks that require abstract logic, though, some researchers have found that interpreting everything through this kind of "language space" can start to cause some problems, even for <a href="https://arstechnica.com/ai/2024/12/openais-new-200-mo-chatgpt-subscription-will-buy-you-more-compute-time/">modern "reasoning" models</a>.</p>
<p>Now, researchers are trying to work around these problems by crafting models that can work out potential logical solutions completely in "latent space"—the hidden computational layer just before the transformer generates language. While this approach doesn't cause a sea change in an LLM's reasoning capabilities, it does show distinct improvements in accuracy for certain types of logical problems and shows some interesting directions for new research.</p>
<h2>Wait, what space?</h2>
<p>Modern reasoning models like ChatGPT's o1 tend to work by generating a "chain of thought." Each step of the logical process in these models is expressed as a sequence of natural language word tokens which are fed back through the model.</p><p><a href="https://arstechnica.com/ai/2024/12/are-llms-capable-of-non-verbal-reasoning/">Read full article</a></p>
<p><a href="https://arstechnica.com/ai/2024/12/are-llms-capable-of-non-verbal-reasoning/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>29</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-1327016094-1152x648.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-1327016094-500x500.jpg" width="500"/>
<media:credit>Getty Images</media:credit><media:text>It's thinking, but not in words.</media:text></media:content>
      </item>
          <item>
        <title>Character.AI steps up teen safety after bots allegedly caused suicide, self-harm</title>
        <link>https://arstechnica.com/tech-policy/2024/12/character-ai-steps-up-teen-safety-after-bots-allegedly-caused-suicide-self-harm/</link>
                  <comments>https://arstechnica.com/tech-policy/2024/12/character-ai-steps-up-teen-safety-after-bots-allegedly-caused-suicide-self-harm/#comments</comments>
        
        <dc:creator>
          <![CDATA[Ashley Belanger]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 21:15:11 +0000</pubDate>
        		<category><![CDATA[Policy]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Character.AI]]></category>
		<category><![CDATA[chatbots]]></category>
		<category><![CDATA[child safety]]></category>
		<category><![CDATA[suicide]]></category>
        <guid isPermaLink="true">https://arstechnica.com/tech-policy/2024/12/character-ai-steps-up-teen-safety-after-bots-allegedly-caused-suicide-self-harm/</guid>

                  <description>
            <![CDATA[Character.AI's new model for teens doesn't resolve all of parents' concerns.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>Following a pair of lawsuits alleging that chatbots caused a <a href="https://arstechnica.com/tech-policy/2024/10/chatbots-posed-as-therapist-and-adult-lover-in-teen-suicide-case-lawsuit-says/">teen boy's suicide</a>, <a href="https://arstechnica.com/tech-policy/2024/12/chatbots-urged-teen-to-self-harm-suggested-murdering-parents-lawsuit-says/">groomed a 9-year-old girl, and caused a vulnerable teen to self-harm</a>, Character.AI (C.AI) has <a href="https://blog.character.ai/how-character-ai-prioritizes-teen-safety/">announced</a> a separate model just for teens, ages 13 and up, that's supposed to make their experiences with bots safer.</p>
<p>In a blog, C.AI said it took a month to develop the teen model, with the goal of guiding the existing model "away from certain responses or interactions, reducing the likelihood of users encountering, or prompting the model to return, sensitive or suggestive content."</p>
<p>C.AI said "evolving the model experience" to reduce the likelihood kids are engaging in harmful chats—including bots allegedly teaching a teen with high-functioning autism to self-harm and delivering inappropriate adult content to all kids whose families are suing—it had to tweak both model inputs and outputs.</p><p><a href="https://arstechnica.com/tech-policy/2024/12/character-ai-steps-up-teen-safety-after-bots-allegedly-caused-suicide-self-harm/">Read full article</a></p>
<p><a href="https://arstechnica.com/tech-policy/2024/12/character-ai-steps-up-teen-safety-after-bots-allegedly-caused-suicide-self-harm/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>26</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-1354022389-1152x648.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-1354022389-500x500.jpg" width="500"/>
<media:credit>Marina Demidiuk | iStock / Getty Images Plus</media:credit></media:content>
      </item>
          <item>
        <title>Critical WordPress plugin vulnerability under active exploit threatens thousands</title>
        <link>https://arstechnica.com/security/2024/12/thousands-of-sites-remain-unpatched-against-actively-exploited-wordpress-plugin-bug/</link>
                  <comments>https://arstechnica.com/security/2024/12/thousands-of-sites-remain-unpatched-against-actively-exploited-wordpress-plugin-bug/#comments</comments>
        
        <dc:creator>
          <![CDATA[Dan Goodin]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 21:00:30 +0000</pubDate>
        		<category><![CDATA[Biz & IT]]></category>
		<category><![CDATA[Security]]></category>
		<category><![CDATA[CMS]]></category>
		<category><![CDATA[exploits]]></category>
		<category><![CDATA[plugins]]></category>
		<category><![CDATA[vulnerabilities]]></category>
		<category><![CDATA[wordpress]]></category>
        <guid isPermaLink="true">https://arstechnica.com/security/2024/12/thousands-of-sites-remain-unpatched-against-actively-exploited-wordpress-plugin-bug/</guid>

                  <description>
            <![CDATA[Vulnerability with severity rating of 9.8 out of possible 10 still live on >8,000 sites.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>Thousands of sites running WordPress remain unpatched against a critical security flaw in a widely used plugin that was being actively exploited in attacks that allow for unauthenticated execution of malicious code, security researchers said.</p>
<p>The vulnerability, tracked as <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2024-11972">CVE-2024-11972</a>, is found in <a href="https://wordpress.org/plugins/hunk-companion/#description">Hunk Companion</a>, a plugin that runs on 10,000 sites that use the WordPress content management system. The vulnerability, which carries a severity rating of 9.8 out of a possible 10, was patched earlier this week. At the time this post went live on Ars, figures provided on the Hunk Companion page indicated that less than 12 percent of users had installed the patch, meaning nearly 9,000 sites could be next to be targeted.</p>
<h2>Significant, multifaceted threat</h2>
<p>“This vulnerability represents a significant and multifaceted threat, targeting sites that use both a ThemeHunk theme and the Hunk Companion plugin,” Daniel Rodriguez, a researcher with WordPress security firm WP Scan, <a href="https://wpscan.com/blog/unauthorized-plugin-installation-activation-in-hunk-companion/">wrote</a>. “With over 10,000 active installations, this exposed thousands of websites to anonymous, unauthenticated attacks capable of severely compromising their integrity.”</p><p><a href="https://arstechnica.com/security/2024/12/thousands-of-sites-remain-unpatched-against-actively-exploited-wordpress-plugin-bug/">Read full article</a></p>
<p><a href="https://arstechnica.com/security/2024/12/thousands-of-sites-remain-unpatched-against-actively-exploited-wordpress-plugin-bug/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>9</slash:comments>
        
        
        <media:content medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2023/07/exploit-vulnerability-security-1.jpg">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2023/07/exploit-vulnerability-security-1-500x500.jpg" width="500"/>
<media:credit>Getty Images</media:credit></media:content>
      </item>
          <item>
        <title>Report: AT&amp;T, Verizon aren’t notifying most victims of Chinese call-records hack</title>
        <link>https://arstechnica.com/tech-policy/2024/12/report-att-verizon-arent-notifying-most-victims-of-chinese-call-records-hack/</link>
                  <comments>https://arstechnica.com/tech-policy/2024/12/report-att-verizon-arent-notifying-most-victims-of-chinese-call-records-hack/#comments</comments>
        
        <dc:creator>
          <![CDATA[Jon Brodkin]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 20:50:50 +0000</pubDate>
        		<category><![CDATA[Policy]]></category>
		<category><![CDATA[AT&T]]></category>
		<category><![CDATA[salt typhoon]]></category>
		<category><![CDATA[verizon]]></category>
        <guid isPermaLink="true">https://arstechnica.com/tech-policy/2024/12/report-att-verizon-arent-notifying-most-victims-of-chinese-call-records-hack/</guid>

                  <description>
            <![CDATA[Telcos reportedly aren't telling users about call metadata taken in Chinese hack.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>AT&amp;T and Verizon reportedly are not notifying most customers whose call records were stolen in the ongoing attack attributed to Chinese hacking group Salt Typhoon. NBC News <a href="https://www.nbcnews.com/tech/security/phone-hack-data-chinese-salt-typhoon-metadata-fbi-security-encrypt-rcna183233">reported today</a> that "the vast majority of people whose call records have been stolen by Chinese hackers have not been notified, according to industry sources, and there is no indication that most affected people will be notified in the near future."</p>
<p>US government officials <a href="https://arstechnica.com/tech-policy/2024/12/us-recommends-encrypted-messaging-as-chinese-hackers-linger-in-telecom-networks/">said last week</a> that major telecom companies have been unable to fully evict the Chinese state-sponsored hackers from their networks. There have been direct notifications to specific targets, such as government officials, whose calls were listened to and whose text messages were accessed. "President-elect Donald Trump, Vice President-elect JD Vance, senior congressional staffers and an array of US security officials were among scores of individuals to have their calls and texts directly targeted," The Wall Street Journal <a href="https://www.wsj.com/politics/national-security/dozens-of-countries-hit-in-chinese-telecom-hacking-campaign-top-u-s-official-says-2a3a5cca">wrote</a>.</p>
<p>For most other victims, the data accessed apparently didn't include the contents of communications. It instead consisted of metadata like the numbers that phones called and when. These people are not receiving notifications from carriers, NBC News wrote today:</p><p><a href="https://arstechnica.com/tech-policy/2024/12/report-att-verizon-arent-notifying-most-victims-of-chinese-call-records-hack/">Read full article</a></p>
<p><a href="https://arstechnica.com/tech-policy/2024/12/report-att-verizon-arent-notifying-most-victims-of-chinese-call-records-hack/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>14</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/phone-1152x648-1734035098.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/phone-500x500-1734035086.jpg" width="500"/>
<media:credit>Getty Images | Tim Robberts</media:credit></media:content>
      </item>
          <item>
        <title>Generating power with a thin, flexible thermoelectric film</title>
        <link>https://arstechnica.com/science/2024/12/thermoelectric-material-gets-flexible-efficient/</link>
                  <comments>https://arstechnica.com/science/2024/12/thermoelectric-material-gets-flexible-efficient/#comments</comments>
        
        <dc:creator>
          <![CDATA[Jacek Krywko]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 19:00:54 +0000</pubDate>
        		<category><![CDATA[Science]]></category>
		<category><![CDATA[cooling]]></category>
		<category><![CDATA[materials science]]></category>
		<category><![CDATA[power]]></category>
		<category><![CDATA[thermoelectric material]]></category>
        <guid isPermaLink="true">https://arstechnica.com/science/2024/12/thermoelectric-material-gets-flexible-efficient/</guid>

                  <description>
            <![CDATA[Device could be integrated into clothing, harvest body heat to power gadgets.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>The No. 1 nuisance with smartphones and smartwatches is that we need to charge them every day. As warm-blooded creatures, however, we generate heat all the time, and that heat can be converted into electricity for some of the electronic gadgetry we carry.</p>
<p>Flexible thermoelectric devices, or F-TEDs, can convert thermal energy into electric power. The problem is that F-TEDs weren’t actually flexible enough to comfortably wear or efficient enough to power even a smartwatch. They were also very expensive to make.</p>
<p>But now, a team of Australian researchers thinks they finally achieved a breakthrough that might take F-TEDs off the ground.</p><p><a href="https://arstechnica.com/science/2024/12/thermoelectric-material-gets-flexible-efficient/">Read full article</a></p>
<p><a href="https://arstechnica.com/science/2024/12/thermoelectric-material-gets-flexible-efficient/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>23</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-1511416656-1152x648.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-1511416656-500x500.jpg" width="500"/>
</media:content>
      </item>
          <item>
        <title>Studies pin down exactly when humans and Neanderthals swapped DNA</title>
        <link>https://arstechnica.com/science/2024/12/studies-pin-down-exactly-when-humans-and-neanderthals-swapped-dna/</link>
                  <comments>https://arstechnica.com/science/2024/12/studies-pin-down-exactly-when-humans-and-neanderthals-swapped-dna/#comments</comments>
        
        <dc:creator>
          <![CDATA[Kiona N. Smith]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 19:00:01 +0000</pubDate>
        		<category><![CDATA[Science]]></category>
		<category><![CDATA[ancient DNA]]></category>
		<category><![CDATA[ancient genomics]]></category>
		<category><![CDATA[ancient people did stuff]]></category>
		<category><![CDATA[anthropology]]></category>
		<category><![CDATA[Archaeology]]></category>
		<category><![CDATA[Neanderthals]]></category>
		<category><![CDATA[out of africa]]></category>
        <guid isPermaLink="true">https://arstechnica.com/science/2024/12/studies-pin-down-exactly-when-humans-and-neanderthals-swapped-dna/</guid>

                  <description>
            <![CDATA[We may owe our tiny sliver of Neanderthal DNA to just a couple of hundred Neanderthals.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>Two recent studies suggest that the gene flow (as the young people call it these days) between Neanderthals and our species happened during a short period sometime between 50,000 and 43,500 years ago. The studies, which share several co-authors, suggest that our torrid history with Neanderthals may have been shorter than we thought.</p>
<h2><b>Pinpointing exactly when Neanderthals met <em>H. sapiens</em>  </b></h2>
<p>Max Planck Institute of Evolutionary Anthropology scientist Leonardo Iasi and his colleagues examined the genomes of 59 people who lived in Europe between 45,000 and 2,200 years ago, plus those of 275 modern people whose ancestors hailed from all over the world. The researchers cataloged the segments of Neanderthal DNA in each person’s genome, then compared them to see where those segments appeared and how that changed over time and distance. This revealed how Neanderthal ancestry got passed around as people spread around the world and provided an estimate of when it all started.</p>
<p>“We tried to compare where in the genomes these [Neanderthal segments] occur and if the positions are shared among individuals or if there are many unique segments that you find [in people from different places],” said University of California Berkeley geneticist Priya Moorjani in a recent press conference. “We find the majority of the segments are shared, and that would be consistent with the fact that there was a single gene flow event.”</p><p><a href="https://arstechnica.com/science/2024/12/studies-pin-down-exactly-when-humans-and-neanderthals-swapped-dna/">Read full article</a></p>
<p><a href="https://arstechnica.com/science/2024/12/studies-pin-down-exactly-when-humans-and-neanderthals-swapped-dna/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>36</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/Ranis-Zlaty-Kun-1152x648.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/Ranis-Zlaty-Kun-500x500.jpg" width="500"/>
<media:credit>Sumer et al. 2024</media:credit><media:text>The artist's illustration shows what the six people buried at the Ranis site, who lived between 49, 500 and 41,000 years ago, may have looked like. Two of these people are mother and daughter, and the mother is a distant cousin (or perhaps a great-great-grandparent or great-great-grandchild) to a woman whose skull was found 130 kilometers away in what's now Czechia.</media:text></media:content>
      </item>
          <item>
        <title>OpenAI introduces “Santa Mode” to ChatGPT for ho-ho-ho voice chats</title>
        <link>https://arstechnica.com/information-technology/2024/12/openai-introduces-santa-mode-to-chatgpt-for-ho-ho-ho-voice-chats/</link>
                  <comments>https://arstechnica.com/information-technology/2024/12/openai-introduces-santa-mode-to-chatgpt-for-ho-ho-ho-voice-chats/#comments</comments>
        
        <dc:creator>
          <![CDATA[Benj Edwards]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 18:50:27 +0000</pubDate>
        		<category><![CDATA[AI]]></category>
		<category><![CDATA[Biz & IT]]></category>
		<category><![CDATA[machine learning]]></category>
        <guid isPermaLink="true">https://arstechnica.com/information-technology/2024/12/openai-introduces-santa-mode-to-chatgpt-for-ho-ho-ho-voice-chats/</guid>

                  <description>
            <![CDATA[An AI version of old St. Nick arrives as a seasonal character in popular chatbot app.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>On Thursday, OpenAI announced that <a href="https://arstechnica.com/information-technology/2024/07/when-counting-quickly-openais-new-voice-mode-stops-to-catch-its-breath/">ChatGPT</a> users can now talk to a simulated version of Santa Claus through the app's voice mode, using AI to bring a North Pole connection to mobile devices, desktop apps, and web browsers during the holiday season.</p>
<p>The company added Santa's voice and personality as a preset option in ChatGPT's <a href="https://arstechnica.com/ai/2024/09/talking-to-chatgpt-for-the-first-time-is-a-surreal-experience/">Advanced Voice Mode</a>. Users can access Santa by tapping a snowflake icon next to the prompt bar or through voice settings. The feature works on iOS and Android mobile apps, chatgpt.com, and OpenAI's Windows and MacOS applications. The Santa voice option will remain available to users worldwide until early January.</p>
<p>The conversations with Santa exist as temporary chats that won't save to chat history or affect the model's memory. OpenAI designed this limitation specifically for the holiday feature. Keep that in mind, because if you let your kids talk to Santa, the AI simulation won't remember what kids have told it during previous conversations.</p><p><a href="https://arstechnica.com/information-technology/2024/12/openai-introduces-santa-mode-to-chatgpt-for-ho-ho-ho-voice-chats/">Read full article</a></p>
<p><a href="https://arstechnica.com/information-technology/2024/12/openai-introduces-santa-mode-to-chatgpt-for-ho-ho-ho-voice-chats/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>32</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/santa_claus_secret_header-1152x648.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/santa_claus_secret_header-500x500.jpg" width="500"/>
<media:credit>inhauscreative via Getty Images</media:credit><media:text>You're supposed to lay your finger aside your nose, Santa, not up your nose.</media:text></media:content>
      </item>
          <item>
        <title>The optical disc onslaught continues, with LG quitting Blu-ray players</title>
        <link>https://arstechnica.com/gadgets/2024/12/the-optical-disc-onslaught-continues-with-lg-quitting-blu-ray-players/</link>
                  <comments>https://arstechnica.com/gadgets/2024/12/the-optical-disc-onslaught-continues-with-lg-quitting-blu-ray-players/#comments</comments>
        
        <dc:creator>
          <![CDATA[Scharon Harding]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 18:38:11 +0000</pubDate>
        		<category><![CDATA[Tech]]></category>
		<category><![CDATA[Blu-ray]]></category>
		<category><![CDATA[dvd]]></category>
		<category><![CDATA[LG]]></category>
		<category><![CDATA[streaming]]></category>
        <guid isPermaLink="true">https://arstechnica.com/gadgets/2024/12/the-optical-disc-onslaught-continues-with-lg-quitting-blu-ray-players/</guid>

                  <description>
            <![CDATA[Streaming uncertainty has some people clinging to their discs. ]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>Like with much of physical media, the onslaught against optical media is ongoing. In the latest hit against physical media fans, LG has discontinued its remaining Blu-ray players. However, this doesn't spell the end for Blu-rays, which, in at least some categories, are seeing growing interest.</p>
<p>LG has no plans to make more Blu-ray players, <a href="https://www.flatpanelshd.com/news.php?subaction=showfull&amp;id=1733902062">FlatpanelsHD</a> reported on Wednesday. Its most recent players, the <a href="http://www.lg.com/us/blu-ray-dvd-players/lg-ubk90-blu-ray-player">UBK90</a> and <a href="http://www.lg.com/us/blu-ray-dvd-players/lg-ubk80-blu-ray-player">UBK80</a>, came out in 2018 and are no longer available for purchase on LG’s website. You can still find them at third-party retailers, but when stock runs out, LG won’t be replenishing. Trying to access LG's "Blu-ray &amp; DVD Players" webpage now results in a redirect to LG's 4K TVs. We can take a hint, LG.</p>
<p>FlatpanelsHD spoke with LG Korea, which reportedly didn’t commit to a permanent exit from Blu-ray players. But for the foreseeable future, the company won’t be selling a type of device that it hasn’t updated in almost seven years.</p><p><a href="https://arstechnica.com/gadgets/2024/12/the-optical-disc-onslaught-continues-with-lg-quitting-blu-ray-players/">Read full article</a></p>
<p><a href="https://arstechnica.com/gadgets/2024/12/the-optical-disc-onslaught-continues-with-lg-quitting-blu-ray-players/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>129</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-2162965259-1152x648.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-2162965259-500x500.jpg" width="500"/>
<media:credit>Getty</media:credit></media:content>
      </item>
          <item>
        <title>Google steps into “extended reality” once again with Android XR</title>
        <link>https://arstechnica.com/gadgets/2024/12/google-steps-into-extended-reality-once-again-with-android-xr/</link>
                  <comments>https://arstechnica.com/gadgets/2024/12/google-steps-into-extended-reality-once-again-with-android-xr/#comments</comments>
        
        <dc:creator>
          <![CDATA[Kevin Purdy]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 18:18:32 +0000</pubDate>
        		<category><![CDATA[Apple]]></category>
		<category><![CDATA[Tech]]></category>
		<category><![CDATA[android]]></category>
		<category><![CDATA[android xr]]></category>
		<category><![CDATA[extended reality]]></category>
		<category><![CDATA[google]]></category>
		<category><![CDATA[Google Glass]]></category>
		<category><![CDATA[VR]]></category>
		<category><![CDATA[XR]]></category>
        <guid isPermaLink="true">https://arstechnica.com/gadgets/2024/12/google-steps-into-extended-reality-once-again-with-android-xr/</guid>

                  <description>
            <![CDATA[No pricing or availability, but there's new competition in headsets and glasses.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>Citing "years of investment in AI, AR, and VR," Google is stepping into the augmented reality market once more with <a href="https://www.android.com/xr/">Android XR</a>. It's an operating system that Google says will power future headsets and glasses that "transform how you watch, work, and explore."</p>
<p>The first version you'll see is Project Moohan, a mixed-reality headset built by Samsung. It will be available for purchase next year, and not much more is known about it. Developers have access to <a href="https://android-developers.googleblog.com/2024/12/introducing-android-xr-sdk-developer-preview.html">the new XR version of Android</a> now.</p>
<p>"We've been in this space since Google Glass, and we have not stopped," said Juston Payne, director of product at Google for XR in <a href="https://www.youtube.com/watch?v=Pn5uG1ys-pE">Android XR's launch video</a>. Citing established projects like Google Lens, Live View for Maps, instant camera translation, and, of course, Google's general-purpose Gemini AI, XR promises to offer such overlays in both dedicated headsets and casual glasses.</p><p><a href="https://arstechnica.com/gadgets/2024/12/google-steps-into-extended-reality-once-again-with-android-xr/">Read full article</a></p>
<p><a href="https://arstechnica.com/gadgets/2024/12/google-steps-into-extended-reality-once-again-with-android-xr/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>32</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/project_moohan-1152x648.jpeg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/project_moohan-500x500.jpeg" width="500"/>
<media:credit>Samsung</media:credit><media:text>Rendering of "Project Moohan," the likely first AR headset that will run Android XR, designed by Samsung.</media:text></media:content>
      </item>
          <item>
        <title>Intel Arc B580 review: A $249 RTX 4060 killer, one-and-a-half years later</title>
        <link>https://arstechnica.com/gadgets/2024/12/review-intel-arc-b580-is-a-compelling-if-incredibly-tardy-250-midrange-gpu/</link>
                  <comments>https://arstechnica.com/gadgets/2024/12/review-intel-arc-b580-is-a-compelling-if-incredibly-tardy-250-midrange-gpu/#comments</comments>
        
        <dc:creator>
          <![CDATA[Andrew Cunningham]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 17:50:18 +0000</pubDate>
        		<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Tech]]></category>
		<category><![CDATA[Alchemist]]></category>
		<category><![CDATA[battlemage]]></category>
		<category><![CDATA[Intel]]></category>
		<category><![CDATA[Intel Arc]]></category>
		<category><![CDATA[intel arc b580]]></category>
        <guid isPermaLink="true">https://arstechnica.com/gadgets/2024/12/review-intel-arc-b580-is-a-compelling-if-incredibly-tardy-250-midrange-gpu/</guid>

                  <description>
            <![CDATA[Intel has solved the biggest problems with its Arc GPUs, but not the timing.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>Intel doesn't have a ton to show for its dedicated GPU efforts yet.</p>
<p>After much anticipation, many delays, and an anticipatory <a href="https://www.tomshardware.com/news/poor-dx11-performance-arc-gpus-constant-work-in-progress">apology tour for its software quality</a>, Intel launched its first Arc GPUs at the end of 2022. There were things to like about the A770 and A750, but buggy drivers, poor performance in older games, and relatively high power use made them difficult to recommend. They were more notable as curiosities than as consumer graphics cards.</p>
<p>The result, after more than two years on the market, is that Arc GPUs remain a statistical nonentity in the GPU market, according to <a href="https://www.jonpeddie.com/news/shipments-of-graphics-aibs-see-significant-surge-in-q2-2024/">analysts</a> and the <a href="https://store.steampowered.com/hwsurvey/directx/">Steam Hardware Survey</a>. But it was always going to take time—and probably a couple of hardware generations—for Intel to make meaningful headway against entrenched competitors.</p><p><a href="https://arstechnica.com/gadgets/2024/12/review-intel-arc-b580-is-a-compelling-if-incredibly-tardy-250-midrange-gpu/">Read full article</a></p>
<p><a href="https://arstechnica.com/gadgets/2024/12/review-intel-arc-b580-is-a-compelling-if-incredibly-tardy-250-midrange-gpu/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>91</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/IMG_2505-1152x648.jpeg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/IMG_2505-500x500-1733985940.jpeg" width="500"/>
<media:credit>Andrew Cunningham</media:credit><media:text>Intel's Arc B580 design doesn't include LEDs or other frills, but it's a clean-looking design.</media:text></media:content>
      </item>
          <item>
        <title>AI helps ID paint chemistry of Berlin Wall murals</title>
        <link>https://arstechnica.com/science/2024/12/ai-helps-id-paint-chemistry-of-berlin-wall-murals/</link>
                  <comments>https://arstechnica.com/science/2024/12/ai-helps-id-paint-chemistry-of-berlin-wall-murals/#comments</comments>
        
        <dc:creator>
          <![CDATA[Jennifer Ouellette]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 16:59:25 +0000</pubDate>
        		<category><![CDATA[Science]]></category>
		<category><![CDATA[art conservation]]></category>
		<category><![CDATA[Berlin Wall]]></category>
		<category><![CDATA[chemistry]]></category>
		<category><![CDATA[graffiti]]></category>
		<category><![CDATA[neural networks]]></category>
		<category><![CDATA[Raman spectroscopy]]></category>
		<category><![CDATA[street art]]></category>
        <guid isPermaLink="true">https://arstechnica.com/science/2024/12/ai-helps-id-paint-chemistry-of-berlin-wall-murals/</guid>

                  <description>
            <![CDATA[Italian scientists designed a neural network to analyze spectral data from handheld Raman spectroscopy devices.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>The <a href="https://en.wikipedia.org/wiki/Fall_of_the_Berlin_Wall">fall of the Berlin Wall</a> in November 1989 was a seminal moment in 20th century history, paving the way for German reunification. Many segments, both large and small, were preserved for posterity—including portions covered in graffiti or murals. A team of Italian scientists used a combination of spectroscopic analysis and machine learning to study paint chips from wall fragments to learn more about the chemistry of the paints and pigments used, according to a <a href="http://pubs.acs.org/doi/abs/10.1021/jacs.4c12611">new paper</a> published in the Journal of the American Chemical Society.</p>
<p>There has been increased attention in recent years to preserving street art, which is vulnerable both to degradation over time as well as deliberate vandalism. For instance, <a href="https://arstechnica.com/science/2021/04/novel-hydrogels-can-safely-remove-graffiti-from-vandalized-street-art/">in 2021</a>, Italian chemists figured out how to use hydrogels to remove added graffiti from vandalized murals in Florence. (Over-painting by vandals is so chemically similar to the original painting underneath that it is difficult to selectively remove just the over-painting without damaging the original.) Unlike most classic masterpieces of the past, created with paints designed to last centuries, street art is more ephemeral in nature, using materials that lack such longevity.</p>
<p>In many cases, like the Berlin Wall, the painters didn't bother to document the specific materials they used, their application techniques, or other useful information that conservators could use to restore or conserve street art. Modern painting materials are also much more complex, and manufacturers typically do not report specific information on the composition of those materials.</p><p><a href="https://arstechnica.com/science/2024/12/ai-helps-id-paint-chemistry-of-berlin-wall-murals/">Read full article</a></p>
<p><a href="https://arstechnica.com/science/2024/12/ai-helps-id-paint-chemistry-of-berlin-wall-murals/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>16</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/berlin1CROP-1152x648.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/berlin1CROP-500x500.jpg" width="500"/>
<media:credit>Thierry Noir/CC BY-SA 3.0</media:credit><media:text>Segment of the Berlin Wall at Bethaniendamm in Berlin-Kreuzberg, in 1986.</media:text></media:content>
      </item>
          <item>
        <title>Weight loss drugs may also treat addiction, Alzheimer’s, and heart disease</title>
        <link>https://arstechnica.com/health/2024/12/weight-loss-drugs-may-also-treat-addiction-alzheimers-and-heart-disease/</link>
                  <comments>https://arstechnica.com/health/2024/12/weight-loss-drugs-may-also-treat-addiction-alzheimers-and-heart-disease/#comments</comments>
        
        <dc:creator>
          <![CDATA[Ian Johnston and Michael Peel, Financial Times]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 16:20:57 +0000</pubDate>
        		<category><![CDATA[Features]]></category>
		<category><![CDATA[Health]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[GLP-1]]></category>
		<category><![CDATA[Ozempic]]></category>
		<category><![CDATA[syndication]]></category>
		<category><![CDATA[wegovy]]></category>
		<category><![CDATA[weight loss]]></category>
		<category><![CDATA[weight loss drugs]]></category>
        <guid isPermaLink="true">https://arstechnica.com/health/2024/12/weight-loss-drugs-may-also-treat-addiction-alzheimers-and-heart-disease/</guid>

                  <description>
            <![CDATA[Pharmaceutical companies are already cashing in on their other health benefits.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>One of Dr. Mo Sarhan’s patients was experiencing intense cravings for opioids and alcohol when the Florida-based doctor offered him a striking solution: the Eli Lilly weight-loss drug Mounjaro.</p>
<p>“Within days, all of his cravings were gone and he was much more effective in his engagement and treatment. He’s done great since,” Sarhan says.</p>
<p>Sarhan and his colleague Steven Klein at the Caron Treatment Centers in Florida and Pennsylvania have prescribed a range of so-called glucagon-like peptide-1 receptor agonists (GLP-1s) to treat addictions, using them alongside traditional therapies, to around 75 patients.</p><p><a href="https://arstechnica.com/health/2024/12/weight-loss-drugs-may-also-treat-addiction-alzheimers-and-heart-disease/">Read full article</a></p>
<p><a href="https://arstechnica.com/health/2024/12/weight-loss-drugs-may-also-treat-addiction-alzheimers-and-heart-disease/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>100</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/weightloss-list-1152x648.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/weightloss-list-500x500.jpg" width="500"/>
<media:credit>FT montage/Bob Haslett</media:credit></media:content>
      </item>
          <item>
        <title>YouTube TV is hiking prices again after denying “erroneous” report days ago</title>
        <link>https://arstechnica.com/gadgets/2024/12/youtube-tv-raisies-prices-10-per-month-in-2025-citing-content-costs-quality/</link>
                  <comments>https://arstechnica.com/gadgets/2024/12/youtube-tv-raisies-prices-10-per-month-in-2025-citing-content-costs-quality/#comments</comments>
        
        <dc:creator>
          <![CDATA[Kevin Purdy]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 16:03:25 +0000</pubDate>
        		<category><![CDATA[Google]]></category>
		<category><![CDATA[Tech]]></category>
		<category><![CDATA[youtube TV]]></category>
        <guid isPermaLink="true">https://arstechnica.com/gadgets/2024/12/youtube-tv-raisies-prices-10-per-month-in-2025-citing-content-costs-quality/</guid>

                  <description>
            <![CDATA[$83/mo price lines up with Hulu TV Live, and not as far below traditional cable.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>YouTube TV, now <a href="https://arstechnica.com/gadgets/2024/02/youtube-tv-is-the-uss-4th-biggest-cable-tv-provider-with-8-million-subs/">one of the country's leading cable (or cable-ish) television providers</a>, is starting to act like it. The service told customers in an email this morning that prices are going up in the new year, from $73 per month for the Base Plan to $83 on January 13, 2025—just days after suggesting that wasn't happening.</p>
<p>"We don’t make these decisions lightly, and we realize this has an impact on our members," Google's email to subscribers read. "We are committed to bringing you features that are changing the way we watch live TV, like unlimited DVR storage and multiview, and supporting YouTube TV’s breadth of content and vast on-demand library of movies and shows."</p>
<p>Google cited "the rising cost of content and the investments we make in the quality of our service" in announcing the price increase. It noted that customers can pause or cancel their subscription in their Settings and that current trials and promotions will be honored and unchanged.</p><p><a href="https://arstechnica.com/gadgets/2024/12/youtube-tv-raisies-prices-10-per-month-in-2025-citing-content-costs-quality/">Read full article</a></p>
<p><a href="https://arstechnica.com/gadgets/2024/12/youtube-tv-raisies-prices-10-per-month-in-2025-citing-content-costs-quality/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>126</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-646395580-scaled-1152x648-1734018446.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-646395580-scaled-500x500-1734018545.jpg" width="500"/>
<media:credit>Getty Images</media:credit></media:content>
      </item>
          <item>
        <title>In an odd bit of propaganda, Belarus claims to have its own Starlink technology</title>
        <link>https://arstechnica.com/space/2024/12/belarus-claims-to-have-developed-a-starlink-analog-for-its-troops/</link>
                  <comments>https://arstechnica.com/space/2024/12/belarus-claims-to-have-developed-a-starlink-analog-for-its-troops/#comments</comments>
        
        <dc:creator>
          <![CDATA[Eric Berger]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 15:51:35 +0000</pubDate>
        		<category><![CDATA[Space]]></category>
		<category><![CDATA[Belarus]]></category>
		<category><![CDATA[space]]></category>
		<category><![CDATA[starlink]]></category>
        <guid isPermaLink="true">https://arstechnica.com/space/2024/12/belarus-claims-to-have-developed-a-starlink-analog-for-its-troops/</guid>

                  <description>
            <![CDATA[Mom, can we have a Starlink? Mom: We have a Starlink at home.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>In recent days, there has been a smattering of coverage in state-run Russian media outlets about how the Belarusian army has developed its own satellite Internet service akin to SpaceX's Starlink constellation, called "Kulisa."</p>
<p>According to <a href="https://tass-ru.translate.goog/mezhdunarodnaya-panorama/22634445?_x_tr_sl=auto&amp;_x_tr_tl=en&amp;_x_tr_hl=de&amp;_x_tr_pto=wapp">the TASS news service</a>, for example, the Kulisa mobile communications technology has "already entered service and is being used in military units of the Armed Forces."</p>
<p><a href="https://news-pravda.com/usa/2024/12/11/913670.html">And Pravda</a>, which started out as the official newspaper of Russia's Communist Party more than a century ago, taunted the developer of the technology, saying, "How's that for you, SpaceX?"</p><p><a href="https://arstechnica.com/space/2024/12/belarus-claims-to-have-developed-a-starlink-analog-for-its-troops/">Read full article</a></p>
<p><a href="https://arstechnica.com/space/2024/12/belarus-claims-to-have-developed-a-starlink-analog-for-its-troops/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>48</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/belarus-1-571x648.jpg" width="571">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/belarus-1-500x500.jpg" width="500"/>
<media:credit>Pravda</media:credit><media:text>The first, and only, president of Belarus, Alexander Lukashenko, is shown the Kulisa technology.</media:text></media:content>
      </item>
          <item>
        <title>NASA’s boss-to-be proclaims we’re about to enter an “age of experimentation”</title>
        <link>https://arstechnica.com/space/2024/12/trumps-nominee-to-lead-nasa-favors-a-full-embrace-of-commercial-space/</link>
                  <comments>https://arstechnica.com/space/2024/12/trumps-nominee-to-lead-nasa-favors-a-full-embrace-of-commercial-space/#comments</comments>
        
        <dc:creator>
          <![CDATA[Stephen Clark]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 14:11:56 +0000</pubDate>
        		<category><![CDATA[Science]]></category>
		<category><![CDATA[Space]]></category>
		<category><![CDATA[artemis]]></category>
		<category><![CDATA[human spaceflight]]></category>
		<category><![CDATA[jared isaacman]]></category>
		<category><![CDATA[moon]]></category>
		<category><![CDATA[NASA]]></category>
		<category><![CDATA[starship]]></category>
        <guid isPermaLink="true">https://arstechnica.com/space/2024/12/trumps-nominee-to-lead-nasa-favors-a-full-embrace-of-commercial-space/</guid>

                  <description>
            <![CDATA["You can get into a rhythm of using all of these providers to get things up very quickly."]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>ORLANDO, Florida<span class="s1">—On Wednesday, </span>Jared Isaacman made his first public appearance since his nomination earlier this month to become NASA's next administrator. Although his remarks were short on specifics, Isaacman endorsed a vision that would signal radical departures from the way NASA does business.</p>
<p>He talked of commercial investment, a thriving space economy, and going fast and taking risks. These talking points are familiar to anyone who has listened to NASA's leadership in recent years, and there has been tangible progress in the agency's partnerships with commercial companies. However, NASA is leaving some commercial expertise on the field, or in this case, on the ground.</p>
<p class="p1"><span class="s1">"I love all about the commercial space industry right now," Isaacman said in a discussion at the Space Force Association's Spacepower Conference in Orlando, Florida. "They’re all generally doing the same thing, which is putting a lot of their own dollars on the line because they believe in the future that it holds."</span></p><p><a href="https://arstechnica.com/space/2024/12/trumps-nominee-to-lead-nasa-favors-a-full-embrace-of-commercial-space/">Read full article</a></p>
<p><a href="https://arstechnica.com/space/2024/12/trumps-nominee-to-lead-nasa-favors-a-full-embrace-of-commercial-space/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>106</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/isaacman2-1152x648.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/isaacman2-500x500.jpg" width="500"/>
<media:credit>John Kraus</media:credit><media:text>Jared Isaacman, President-elect Trump's nominee to be the next NASA administrator, speaks at the Spacepower Conference on Wednesday in Orlando, Florida.</media:text></media:content>
      </item>
          <item>
        <title>Back where it started: “Do Not Track” removed from Firefox after 13 years</title>
        <link>https://arstechnica.com/gadgets/2024/12/firefox-one-of-the-first-do-not-track-supporters-no-longer-offers-it/</link>
                  <comments>https://arstechnica.com/gadgets/2024/12/firefox-one-of-the-first-do-not-track-supporters-no-longer-offers-it/#comments</comments>
        
        <dc:creator>
          <![CDATA[Kevin Purdy]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 12:00:32 +0000</pubDate>
        		<category><![CDATA[Tech]]></category>
        <guid isPermaLink="true">https://arstechnica.com/gadgets/2024/12/firefox-one-of-the-first-do-not-track-supporters-no-longer-offers-it/</guid>

                  <description>
            <![CDATA[A brief history of the privacy you never really got.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>It might not ever be fully dead, but Firefox calling it quits on Do Not Track (DNT) is a strong indication that an idealistic movement born more than 13 years ago has truly reached the end of its viable life.</p>
<p><a href="https://windowsreport.com/mozilla-firefox-removes-do-not-track-feature-support-heres-what-it-means-for-your-privacy/">The Windows Report tech news site spotted</a> that Firefox has removed the option to "Send websites a 'Do Not Track' request" as of version 135, already visible in Nightly builds. Users checking the Website Privacy Preference section will soon see a linked notice that Firefox will no longer support the signal. Firefox's <a href="https://support.mozilla.org/en-US/kb/how-do-i-turn-do-not-track-feature">support page for Do Not Track</a> notes that "Many sites do not respect this indication of a person's privacy preferences, and, in some cases, it can reduce privacy."</p>
<p>Google Chrome and Microsoft Edge (based in part on Chrome's open source origin, Chromium) still offer a Do Not Track option, but they are just as ineffective. <a href="https://arstechnica.com/tech-policy/2020/10/coming-to-a-browser-near-you-a-new-way-to-keep-sites-from-selling-your-data/">Global Privacy Control</a> has largely superseded Do Not Track as a supported—and, in some places, legislated—means of signaling a desire not to be tracked.</p><p><a href="https://arstechnica.com/gadgets/2024/12/firefox-one-of-the-first-do-not-track-supporters-no-longer-offers-it/">Read full article</a></p>
<p><a href="https://arstechnica.com/gadgets/2024/12/firefox-one-of-the-first-do-not-track-supporters-no-longer-offers-it/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>79</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/broken_cookie-1152x648.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/broken_cookie-500x500.jpg" width="500"/>
<media:credit>Getty Images</media:credit></media:content>
      </item>
          <item>
        <title>Dodge keeps true to its roots with the first electric Charger muscle car</title>
        <link>https://arstechnica.com/culture/2024/12/dodge-keeps-true-to-its-roots-with-the-first-electric-charger-muscle-car/</link>
                  <comments>https://arstechnica.com/culture/2024/12/dodge-keeps-true-to-its-roots-with-the-first-electric-charger-muscle-car/#comments</comments>
        
        <dc:creator>
          <![CDATA[Jonathan M. Gitlin]]>
        </dc:creator>
        <pubDate>Thu, 12 Dec 2024 05:01:08 +0000</pubDate>
        		<category><![CDATA[Cars]]></category>
		<category><![CDATA[Culture]]></category>
		<category><![CDATA[car review]]></category>
		<category><![CDATA[Dodge Charger]]></category>
		<category><![CDATA[First drive]]></category>
        <guid isPermaLink="true">https://arstechnica.com/culture/2024/12/dodge-keeps-true-to-its-roots-with-the-first-electric-charger-muscle-car/</guid>

                  <description>
            <![CDATA[The big two-door electric sedan impressed on the road, less so on track.]]>
          </description>
                                <content:encoded>
              <![CDATA[<aside class="pullbox sidebar fullwidth">Dodge provided flights from Washington to Phoenix and accommodation so Ars could drive the new Charger Daytona. Ars does not accept paid editorial content.</aside>
<p>PHOENIX—Dodge gave its development team a relatively simple brief for the new Charger: It had to look, drive, and sound like a traditional Dodge muscle car. "If we don't make people uncomfortable, where are we going," asked Matt McAleer, Dodge and SRT's CEO. And you can see what he means: customers will have a choice of battery-electric or, from next year, an inline-six gasoline engine. For now, there is no throbbing V8 version, and those options will surely make some Dodge muscle car purists a little uncomfortable.</p>
<p>But the new car certainly looks the part. According to Scott Krueger, vice president for exterior design at Dodge, the stylists' aimed for "heritage, not retro," and they achieved that with a sedan shape that certainly evokes the classic 1968 Charger without directly copying any of its lines. It's a car that looks great in the metal, and features like the LED strip of daylight running lights and the so-called "R-wing" at the front ensure that the design feels thoroughly modern and not a pastiche.</p>
<img width="2560" height="1920" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/2025-Dodge-Charger-Daytona-2-scaled.jpg" class="fullwidth full" alt="A white Dodge Charger Daytona seen in profile against some garages at a race track" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/12/2025-Dodge-Charger-Daytona-2-scaled.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/2025-Dodge-Charger-Daytona-2-640x480.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/2025-Dodge-Charger-Daytona-2-1024x768.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/2025-Dodge-Charger-Daytona-2-768x576.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/2025-Dodge-Charger-Daytona-2-1536x1152.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/2025-Dodge-Charger-Daytona-2-2048x1536.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/2025-Dodge-Charger-Daytona-2-980x735.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/2025-Dodge-Charger-Daytona-2-1440x1080.jpg 1440w" sizes="auto, (max-width: 2560px) 100vw, 2560px">
      The Charger Daytona name is just for the BEV variant—when the straight-six Charger debuts next year it won't be a Daytona.
        Credit:
          Jonathan Gitlin
      
<p>It's not exactly compact, though—at 206.9 inches (5,248 mm) long, 78.1 inches (2,028 mm) wide, and 58.9 inches (1,497 mm) tall, the Charger was built with American roads (and parking spaces) in mind, and is in fact 2 inches (50 mm) wider than the outgoing Charger Hellcat widebody.</p><p><a href="https://arstechnica.com/culture/2024/12/dodge-keeps-true-to-its-roots-with-the-first-electric-charger-muscle-car/">Read full article</a></p>
<p><a href="https://arstechnica.com/culture/2024/12/dodge-keeps-true-to-its-roots-with-the-first-electric-charger-muscle-car/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>181</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/2025-Dodge-Charger-Daytona-1-scaled-1152x648-1733942103.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/2025-Dodge-Charger-Daytona-1-500x500.jpg" width="500"/>
<media:credit>Jonathan Gitlin</media:credit></media:content>
      </item>
          <item>
        <title>Russia takes unusual route to hack Starlink-connected devices in Ukraine</title>
        <link>https://arstechnica.com/security/2024/12/russia-takes-unusual-route-to-hack-starlink-connected-devices-in-ukraine/</link>
                  <comments>https://arstechnica.com/security/2024/12/russia-takes-unusual-route-to-hack-starlink-connected-devices-in-ukraine/#comments</comments>
        
        <dc:creator>
          <![CDATA[Dan Goodin]]>
        </dc:creator>
        <pubDate>Wed, 11 Dec 2024 23:18:42 +0000</pubDate>
        		<category><![CDATA[Biz & IT]]></category>
		<category><![CDATA[Security]]></category>
		<category><![CDATA[backdoors]]></category>
		<category><![CDATA[nation state hacking]]></category>
		<category><![CDATA[phishing]]></category>
		<category><![CDATA[turla]]></category>
        <guid isPermaLink="true">https://arstechnica.com/security/2024/12/russia-takes-unusual-route-to-hack-starlink-connected-devices-in-ukraine/</guid>

                  <description>
            <![CDATA[Secret Blizzard has used the resources of at least 6 other groups in the past 7 years.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>Russian nation-state hackers have followed an unusual path to gather intel in the country's ongoing invasion of Ukraine—appropriating the infrastructure of fellow threat actors and using it to infect electronic devices its adversary’s military personnel are using on the front line.</p>
<p>On at least two occasions this year, the Russian hacking group, tracked under names including Turla, Waterbug, Snake, and Venomous Bear, has used servers and malware used by separate threat groups in attacks targeting front-line Ukrainian military forces, Microsoft <a href="https://www.microsoft.com/en-us/security/blog/2024/12/11/frequent-freeloader-part-ii-russian-actor-secret-blizzard-using-tools-of-other-groups-to-attack-ukraine/">said</a> Wednesday. In one case, Secret Blizzard—the name Microsoft uses to track the group—leveraged the infrastructure of a cybercrime group tracked as Storm-1919. In the other, Secret Blizzard appropriated resources of Storm-1837, a Russia-based threat actor with a history of targeting Ukrainian drone operators.</p>
<p>The more common means for initial access by Secret Blizzard is spear phishing followed by lateral movement through server-side and edge device compromises. Microsoft said that the threat actor’s pivot here is unusual but not unique. Company investigators still don’t know how Secret Blizzard obtained access to the infrastructure.</p><p><a href="https://arstechnica.com/security/2024/12/russia-takes-unusual-route-to-hack-starlink-connected-devices-in-ukraine/">Read full article</a></p>
<p><a href="https://arstechnica.com/security/2024/12/russia-takes-unusual-route-to-hack-starlink-connected-devices-in-ukraine/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>42</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2021/12/GettyImages-1327354395-1152x648.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2021/12/GettyImages-1327354395-500x500.jpg" width="500"/>
</media:content>
      </item>
          <item>
        <title>Errant reference in macOS 15.2 seems to confirm M4 MacBook Airs for 2025</title>
        <link>https://arstechnica.com/gadgets/2024/12/errant-reference-in-macos-15-2-seems-to-confirm-m4-macbook-airs-for-2025/</link>
                  <comments>https://arstechnica.com/gadgets/2024/12/errant-reference-in-macos-15-2-seems-to-confirm-m4-macbook-airs-for-2025/#comments</comments>
        
        <dc:creator>
          <![CDATA[Andrew Cunningham]]>
        </dc:creator>
        <pubDate>Wed, 11 Dec 2024 22:27:55 +0000</pubDate>
        		<category><![CDATA[Apple]]></category>
		<category><![CDATA[Tech]]></category>
		<category><![CDATA[apple]]></category>
		<category><![CDATA[apple m4]]></category>
		<category><![CDATA[MacBook Air]]></category>
        <guid isPermaLink="true">https://arstechnica.com/gadgets/2024/12/errant-reference-in-macos-15-2-seems-to-confirm-m4-macbook-airs-for-2025/</guid>

                  <description>
            <![CDATA[Software reference could point to a release sooner rather than later.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>The macOS 15.2 update that was released earlier today came with a handful of new features, plus something unexpected: an apparently accidental reference to the upcoming M4 MacBook Airs. MacRumors <a href="https://www.macrumors.com/2024/12/11/macos-sequoia-15-2-m4-macbook-air-leak/">reports</a> that the "Mac16,12" and "Mac16,13" model identifiers reference 13- and 15-inch models of the M4 Air and that both are coming in 2025.</p>
<p>That a MacBook Air refresh is planned for next year isn't much of a surprise at this point—in reporting that pretty much nailed the details of the first M4 Macs, Bloomberg's Mark Gurman <a href="https://arstechnica.com/gadgets/2024/10/report-first-wave-of-m4-macs-including-smaller-mac-mini-coming-november-1/">has said</a> that the Air, the Mac Studio, and the Mac Pro are all slated for updates throughout 2025.</p>
<p>But a reference in the current release of macOS could point to a launch sooner rather than later; the M4 Mac mini was <a href="https://arstechnica.com/gadgets/2024/09/report-big-batch-of-m4-macs-and-cheaper-ipads-on-tap-for-october-apple-event/">referenced in a macOS update</a> in mid-September around a month and a half before it was released. The M3 Airs <a href="https://arstechnica.com/gadgets/2024/03/review-apples-efficient-m3-macbook-airs-are-just-about-as-good-as-laptops-get/">came out in March this year</a>, but Apple has been known to put out new Macs as early as January in recent years.</p><p><a href="https://arstechnica.com/gadgets/2024/12/errant-reference-in-macos-15-2-seems-to-confirm-m4-macbook-airs-for-2025/">Read full article</a></p>
<p><a href="https://arstechnica.com/gadgets/2024/12/errant-reference-in-macos-15-2-seems-to-confirm-m4-macbook-airs-for-2025/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>49</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/IMG_1731-1152x648.jpeg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/IMG_1731-500x500-1733954836.jpeg" width="500"/>
<media:credit>Andrew Cunningham</media:credit><media:text>The 15- and 13-inch M3 MacBook Airs.</media:text></media:content>
      </item>
          <item>
        <title>Photobucket opted inactive users into privacy nightmare, lawsuit says</title>
        <link>https://arstechnica.com/tech-policy/2024/12/photobucket-sold-users-biometric-data-without-consent-lawsuit-says/</link>
                  <comments>https://arstechnica.com/tech-policy/2024/12/photobucket-sold-users-biometric-data-without-consent-lawsuit-says/#comments</comments>
        
        <dc:creator>
          <![CDATA[Ashley Belanger]]>
        </dc:creator>
        <pubDate>Wed, 11 Dec 2024 21:29:09 +0000</pubDate>
        		<category><![CDATA[Policy]]></category>
		<category><![CDATA[biometric data]]></category>
		<category><![CDATA[biometric information privacy act]]></category>
		<category><![CDATA[generative ai]]></category>
		<category><![CDATA[Illinois]]></category>
		<category><![CDATA[myspace]]></category>
		<category><![CDATA[photobucket]]></category>
        <guid isPermaLink="true">https://arstechnica.com/tech-policy/2024/12/photobucket-sold-users-biometric-data-without-consent-lawsuit-says/</guid>

                  <description>
            <![CDATA[Class action could foil Photobucket’s plan to turn old photos into AI goldmine.]]>
          </description>
                                <content:encoded>
              <![CDATA[<p>Photobucket was <a href="https://cdn.arstechnica.net/wp-content/uploads/2024/12/Pierce-v-Photobucket-Complaint-12-11-24.pdf">sued</a> Wednesday after a recent privacy policy update revealed plans to sell users' photos—including biometric identifiers like face and iris scans—to companies training generative AI models.</p>
<p>The proposed class action seeks to stop Photobucket from selling users' data without first obtaining written consent, alleging that Photobucket either intentionally or negligently failed to comply with strict privacy laws in states like Illinois, New York, and California by claiming it can't reliably determine users' geolocation.</p>
<p>Two separate classes could be protected by the litigation. The first includes anyone who ever uploaded a photo between 2003—when Photobucket was founded—and May 1, 2024. Another potentially even larger class includes any non-users depicted in photographs uploaded to Photobucket, whose biometric data has also allegedly been sold without consent.</p><p><a href="https://arstechnica.com/tech-policy/2024/12/photobucket-sold-users-biometric-data-without-consent-lawsuit-says/">Read full article</a></p>
<p><a href="https://arstechnica.com/tech-policy/2024/12/photobucket-sold-users-biometric-data-without-consent-lawsuit-says/#comments">Comments</a></p>
]]>
            </content:encoded>
                  
                  <slash:comments>78</slash:comments>
        
        
        <media:content height="648" medium="image" type="image/jpeg" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-117046657-1152x648.jpg" width="1152">
<media:thumbnail height="500" url="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-117046657-500x500.jpg" width="500"/>
<media:credit>PM Images | Stone</media:credit></media:content>
      </item>
      </channel>
</rss>